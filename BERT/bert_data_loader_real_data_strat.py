# -*- coding: utf-8 -*-
"""bert_data_loader_real_data_strat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zKH23iQZbn-YD2ufFAGMn8LwzYoFFbWw
"""

# https://colab.research.google.com/github/abhimishra91/transformers-tutorials
# https://github.com/abhimishra91/transformers-tutorials

from ast import literal_eval
import matplotlib.pyplot as plt
import pandas as pd
import torch
import numpy as np

from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler

import torch.nn as nn
import torch.optim as optim

from IPython.core.debugger import set_trace
from sklearn import metrics
import seaborn as sns

import pandas as pd
from sklearn.model_selection import train_test_split

from torch import cuda
device = 'cuda' if cuda.is_available() else 'cpu'

# Note: needs transformers 3
import transformers
from transformers import BertTokenizer, BertForSequenceClassification
from transformers import BertTokenizer, BertModel, BertConfig

from pathlib import Path
import time

def log(msg):
    print(msg)
    file.write(f"{msg}\n")

def time_str(msg, end, start):
    delta = end-start 
    time_str = f"{msg}: {delta:.2f} seconds ({delta/3600:.2f} hours)"
    return time_str

d = Path(__file__).parent
d = Path.cwd()
root = Path(d)

train_file = root / "data" / "train.csv"
valid_file = root / "data" / "valid.csv"
test_file = root / "data" / "test.csv"
output_file = root / "log.txt"

code_counts_file = Path(".") / "data" / "codecounts.csv"

if output_file.exists():
    output_file.unlink()

file = open(output_file, "w")

log("Starting...")

# if not train_file.exists():
#   print("Downloading and preparing datafiles.")
#   !mkdir data
#   !wget https://www.dropbox.com/s/4o4m24eybl2jq9c/train.csv.tar.gz?dl=0
#   !wget https://www.dropbox.com/s/en8k3df7a6l1qat/codecounts.csv?dl=0
#   !mv train.csv.tar.gz?dl=0 train.csv.tar.gz
#   !tar -zxvf train.csv.tar.gz
#   !mv train.csv data/.
#   !mv codecounts.csv?dl=0 data/codecounts.csv

#   !wget https://www.dropbox.com/s/nnfyk0gb3s3w22k/test.csv.tar.gz?dl=0
#   !mv test.csv.tar.gz?dl=0 test.csv.tar.gz
#   !tar -zxvf test.csv.tar.gz
#   !mv test.csv data/.

#   !wget https://www.dropbox.com/s/ylpjz7zvra8bdru/valid.csv.tar.gz?dl=0
#   !mv valid.csv.tar.gz?dl=0 valid.csv.tar.gz
#   !tar -zxvf valid.csv.tar.gz
#   !mv valid.csv data/.

# else:
#   print("Datafiles already exists.")

def to_list(x):
    return x.strip("[]").replace("'","").split(", ")

valid_df = pd.read_csv(
    valid_file
    # usecols=["sentences","codes","labels"],
    # converters={
    #     "codes": to_list,
    #     "sentences": to_list,
    #     "labels": to_list,
    # }
)
train_df = pd.read_csv(train_file)
test_df = pd.read_csv(test_file)

df_codes = pd.read_csv(code_counts_file)
pos_weights=torch.tensor(df_codes["weights"].values, device=device)

train_df["codes"] = train_df["codes"].apply(lambda x: literal_eval(x))
valid_df["codes"] = valid_df["codes"].apply(lambda x: literal_eval(x))
test_df["codes"] = test_df["codes"].apply(lambda x: literal_eval(x))

train_df["labels"] = train_df["labels"].apply(lambda x: literal_eval(x))
valid_df["labels"] = valid_df["labels"].apply(lambda x: literal_eval(x))
test_df["labels"] = test_df["labels"].apply(lambda x: literal_eval(x))

train_df["sentences"] = train_df["sentences"].apply(lambda x: literal_eval(x))
valid_df["sentences"] = valid_df["sentences"].apply(lambda x: literal_eval(x))
test_df["sentences"] = test_df["sentences"].apply(lambda x: literal_eval(x))


def trim_string(x, **kwargs):

    first_n_words = kwargs["first_n_words"]

    try:
        x = x.split(maxsplit=first_n_words)
        x = " ".join(x[:first_n_words])
    except AttributeError as e:
        # Catch nan values and use empty string instead.
        x = ""

    return x

def join_sents(sents, first_n_words):
  concatenated_and_trimmed = ""
  try:
    concatenated = " ".join(sents)
    #set_trace()
  except TypeError as e:
    concatenated = " ".join(sents[1:first_n_words+1])
  trimmed = trim_string(concatenated, first_n_words=first_n_words)

  return trimmed


# Max token num
max_tokens = 512

train_df["title_text"] = train_df["sentences"].apply(join_sents, first_n_words=max_tokens)
valid_df["title_text"] = valid_df["sentences"].apply(join_sents, first_n_words=max_tokens)
test_df["title_text"] = test_df["sentences"].apply(join_sents, first_n_words=max_tokens)

#valid_df["len"] = valid_df["title_text"].apply(lambda x: len(x.split()))
#valid_df[valid_df["len"]>512]

target_size = len(df_codes)

# Create a dictionary code_to_index such that
# {
#    'C11': 0,
#    'C12': 1,
#    'C13': 2,
#    ...
# }
index_to_code = pd.DataFrame(df_codes["code"]).to_dict(orient="dict")["code"]
code_to_index = {code: index for index, code in index_to_code.items()}


code_df = pd.DataFrame(list(code_to_index))

num_labels = len(code_to_index)


# Verify label vectors are correct

from more_itertools import locate

# # Get indexes that correspond to labels existing for row z
# z = 10
# has1 = list(locate(train_df["labels"][z], lambda x: x == 1))

# # Display codes that correspond to the indexes, derived from the label vectors
# code_df.iloc[has1]

# train_df

# # Display codes from the original data
# train_df.iloc[10]["title_text"]

# Sections of config

# Defining some key variables that will be used later on in the training
MAX_LEN = max_tokens
TRAIN_BATCH_SIZE = 16
VALID_BATCH_SIZE = 8
EPOCHS = 10
LEARNING_RATE = 1e-05
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

class CustomDataset(Dataset):

    def __init__(self, dataframe, tokenizer, max_len):
        self.tokenizer = tokenizer
        self.data = dataframe
        self.title_text = dataframe.title_text
        self.targets = self.data.labels
        self.max_len = max_len

    def __len__(self):
        return len(self.title_text)

    def __getitem__(self, index):
        # set_trace()
        title_text = str(self.title_text[index])
        title_text = " ".join(title_text.split())

        inputs = self.tokenizer.encode_plus(
            title_text,
            None,
            add_special_tokens=True,
            max_length=self.max_len,
            pad_to_max_length=True,
            return_token_type_ids=True,
            truncation=True
        )
        ids = inputs['input_ids']
        mask = inputs['attention_mask']
        token_type_ids = inputs["token_type_ids"]


        return {
            'ids': torch.tensor(ids, dtype=torch.long),
            'mask': torch.tensor(mask, dtype=torch.long),
            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),
            'targets': torch.tensor(self.targets[index], dtype=torch.float)
        }

# Creating the dataset and dataloader for the neural network

#train_size = 0.8
#train_dataset=new_df.sample(frac=train_size,random_state=200)
#test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)
#train_dataset = train_dataset.reset_index(drop=True)

# Split to train, valid and test sets.
#df_train, df_testvalid = train_test_split(df_essentials, train_size=0.8, random_state=42)
#df_test, df_valid = train_test_split(df_testvalid, train_size=0.5, random_state=42)

size_train = train_df.shape[0]
size_valid = 3000 # valid_df.shape[0]
size_test = test_df.shape[0]
train_dataset = train_df[0:size_train].reset_index(drop=True)
valid_dataset = valid_df[0:size_valid].reset_index(drop=True)
test_dataset = test_df[0:size_test].reset_index(drop=True)


#print("FULL Dataset: {}".format(df_essentials.shape))
log("TRAIN Dataset: {}".format(train_dataset.shape))
log("VALID Dataset: {}".format(valid_dataset.shape))
log("TEST Dataset: {}".format(test_dataset.shape))

training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)
valid_set = CustomDataset(valid_dataset, tokenizer, MAX_LEN)
testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)

calculate_dev_acc_every = (size_train//2)//TRAIN_BATCH_SIZE
calculate_dev_acc_every

train_params = {'batch_size': TRAIN_BATCH_SIZE,
                'shuffle': True,
                'num_workers': 0
                }

test_params = {'batch_size': VALID_BATCH_SIZE,
                'shuffle': True,
                'num_workers': 0
                }

training_loader = DataLoader(training_set, **train_params)
valid_loader = DataLoader(valid_set, **test_params)
testing_loader = DataLoader(testing_set, **test_params)

# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. 

class BERTClass(torch.nn.Module):
    def __init__(self):
        super(BERTClass, self).__init__()
        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')
        self.l2 = torch.nn.Dropout(0.3)
        # Bert base has 768 hidden units.
        self.l3 = torch.nn.Linear(768, target_size)
    
    def forward(self, ids, mask, token_type_ids):
        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)
        output_2 = self.l2(output_1)
        output = self.l3(output_2)
        return output

model = BERTClass()
_tmp = model.to(device)

def loss_fn(outputs, targets):
    return torch.nn.BCEWithLogitsLoss()(outputs, targets)
    # Using this makes the loss jump around instead of decreasing.
    # return torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights)(outputs, targets)

optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)

def validation(dataset_loader):
    model.eval()
    fin_targets=[]
    fin_outputs=[]
    with torch.no_grad():
        for _, data in enumerate(dataset_loader, 0):
            ids = data['ids'].to(device, dtype = torch.long)
            mask = data['mask'].to(device, dtype = torch.long)
            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)
            targets = data['targets'].to(device, dtype = torch.float)
            outputs = model(ids, mask, token_type_ids)
            fin_targets.extend(targets.cpu().detach().numpy().tolist())
            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())
    return fin_outputs, fin_targets

best_f1_score = 0

def train(epoch):
    global best_f1_score
    best_f1_score = 0
    model.train()
    epoch_start_time = time.time()
    for i,data in enumerate(training_loader):
        ids = data['ids'].to(device, dtype = torch.long)
        mask = data['mask'].to(device, dtype = torch.long)
        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)
        targets = data['targets'].to(device, dtype = torch.float)

        outputs = model(ids, mask, token_type_ids)
        #outputs = model(**ids, return_dict=False)

        optimizer.zero_grad()
        loss = loss_fn(outputs, targets)
        if i%calculate_dev_acc_every==0:
            log(f'Epoch: {epoch}, Loss:  {loss.item()}')

            valid_start_time = time.time()
            with torch.no_grad():
                model.eval()
                output_probs, targets = validation(valid_loader)
                outputs = np.array(output_probs) >= 0.5
                #set_trace()
                targets = np.array(targets)
                f1_score_micro = metrics.f1_score(targets, outputs, average='micro', zero_division=0)
                f1_score_macro = metrics.f1_score(targets, outputs, average='macro', zero_division=0)
                log(f"Validation set: F1 Score (Micro) = {f1_score_micro}, F1 Score (Macro) = {f1_score_macro}")
                if f1_score_macro > best_f1_score: 
                  best_f1_score = f1_score_macro
                  # Save the best model so far.
                  torch.save(model.state_dict(), "bert.pth")
            model.train()
            valid_end_time = time.time()
            log(time_str("Validation with dev set took", valid_end_time, valid_start_time))


        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    epoch_end_time = time.time()
    log(time_str("Training for this epoch took", epoch_end_time, epoch_start_time))

log("Training starts")
training_start_time = time.time()
for epoch in range(EPOCHS):
    train(epoch)
training_end_time = time.time()
log(time_str("Training ended. Training took", training_end_time, training_start_time))

log(f"Using model with a macro f1 score of {best_f1_score} for the dev set.")
model.load_state_dict(torch.load("bert.pth"))
log("Evaluating model with the test set.")
for epoch in range(EPOCHS):
    output_probs, targets = validation(testing_loader)
    # Should we tinker with threshold?
    outputs = np.array(output_probs) >= 0.5
    accuracy = metrics.accuracy_score(targets, outputs)
    hamming_loss = metrics.hamming_loss(targets, outputs)
    targets = np.array(targets)
    f1_score_micro = metrics.f1_score(targets, outputs, average='micro', zero_division=0)
    f1_score_macro = metrics.f1_score(targets, outputs, average='macro', zero_division=0)
    log(f"Accuracy Score = {accuracy}")
    log(f"Hamming loss = {hamming_loss}")
    log(f"F1 Score (Micro) = {f1_score_micro}")
    log(f"F1 Score (Macro) = {f1_score_macro}")

# Prediction probabilities for the first item in test set.
out_probs = np.array(output_probs)
out_probs[6,:]

# Classification for the first item in the testset.
outputs[6,:]

ta = np.array(targets)

# Gold labels.
ta[6,:]

# Indexes for tags that correspond to tags that are present in the news.
indexes_1 = np.where(ta[0,:]>0)

# Probabilities for the corresponding indexes.
for i in indexes_1[0]:
  log(out_probs[0,i])


file.close()
